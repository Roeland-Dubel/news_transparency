{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8a98488-c585-470f-a1e7-4b04720df5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We import our necessary libraries.\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm; tqdm.pandas()\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01233671-877c-4324-ae1e-a60b249d973f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We redefine our earlier used metrics label function as used in the script 11 for source presence.\n",
    "def get_metrics_table(y_test, y_pred, feature, model):\n",
    "    rep = pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    print(round(rep, 2))\n",
    "    rep[\"feature\"] = feature; rep[\"model\"] = model\n",
    "    rep[[\"precision\", \"f1-score\", \"recall\"]] = rep[[\"precision\", \"f1-score\", \"recall\"]].apply(lambda x: round(x, 2))\n",
    "    rep[\"support\"] = rep[\"support\"].apply(lambda x: int(x))\n",
    "    rep[\"accuracy\"] = [rep[rep.index==\"accuracy\"].values[0][0]] + 4 * [\" \"] \n",
    "    rep = rep[:2]\n",
    "    rep[\"class\"] = [\"no\", \"yes\"]\n",
    "    rep = rep[[\"feature\", \"model\", \"class\", \"precision\", \"recall\", \"f1-score\", \"support\", \"accuracy\"]][:2]\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c139109-05a1-4359-af34-0b9106659fad",
   "metadata": {},
   "source": [
    "__Does the text give any insight into when, why, how or against which standards the article was created?__\n",
    "\n",
    "- 1 = True\n",
    "- 0 = False\n",
    "\n",
    "Examples are providing explanations of …\n",
    "\n",
    "- The origin of the news and/or news selection processes:\n",
    "    - Dit artikel is een nieuwe versie van een stuk dat we eind vorige maand publiceerden. Omdat de rechter vandaag uitspraak doet, brengen we het opnieuw onder de aandacht.\n",
    "    - Een versie van dit artikel verscheen ook in de krant van 11 oktober 2023.\n",
    "- Internal news standards and/or motives:\n",
    "    - Doordat het negatieve nieuws NU.nl vaak domineert, sneeuwt het positieve nieuws soms onder. Daarom zetten we wekelijks vrolijk stemmende berichten op een rij.\n",
    "- Internal news decisions:\n",
    "    - De NOS heeft ervoor gekozen om geen bedrijven te benaderen die vallen onder elektriciteit, cement en waterstof, omdat daar op dit moment weinig van wordt geïmporteerd van buiten de EU naar Nederland.\n",
    "- News sourcing and production processes:\n",
    "    - De Volkskrant heeft per mail contact gezocht met de King Saud Universiteit, maar geen reactie ontvangen.\n",
    "    - Deze samenvatting is gemaakt met behulp van AI en gecheckt door NU.nl.\n",
    "\n",
    "__Note: It is of importance that the role of the media company and or its workers is proactively disclosed. For instance whereas simply stating which sources are used does not constitute process information, indicating how sources were contacted by the media company and or its workers and/or why sources were used does.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65eddc58-7f71-4be0-a286-5cd3abc66045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We read our annotated data.\n",
    "df_sample = pd.read_csv(\"21_process_info_man.csv\", sep=\";\", encoding=\"utf-8\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f0af15-04b8-47e2-8b7f-cbd8feb944e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We drop faulty read columns.\n",
    "df_sample = df_sample.loc[:, ~df_sample.columns.str.contains(\"Unnamed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6536c5-1feb-4c93-add4-8c0e15be275e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We drop any missing values.\n",
    "df_sample = df_sample.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d8e5e37-ffe9-4ec1-a76d-82b74f820a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We create a function that censors sentences on the presence or absence of the outlet name within the sentence.\n",
    "def get_source_censored(x):\n",
    "    sent = x[\"self_referral_text\"]\n",
    "    news_source = x[\"news_source\"]\n",
    "    source_pattern = f\"\\\\b({news_source}(\\.nl)?)\\\\b\"\n",
    "    \n",
    "    #We search if the outlet name is present.\n",
    "    #If so we replace it by SOURCE and return 1.\n",
    "    if re.search(source_pattern, sent):\n",
    "        sent = re.sub(source_pattern, \"SOURCE\", sent)\n",
    "        return 1, sent\n",
    "    else:\n",
    "        #In any other case we leave the sentence untouched and return it with 0.\n",
    "        return 0, sent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "63f9cf31-fa10-4fbc-9c7a-6d0b19052b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1980/1980 [00:00<00:00, 8751.25it/s] \n"
     ]
    }
   ],
   "source": [
    "#We apply the function to our data.\n",
    "df_sample[[\"news_source_presence\", \"sent_c\"]] = df_sample.progress_apply(lambda x: pd.Series(get_source_censored(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6a56936e-6e5e-43c8-869c-bfa0f183d2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1563, 1: 417})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the presence of outlet names in sentences.\n",
    "Counter(df_sample.news_source_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ac56524-d046-46df-b065-1a8141e7837b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We make sure that our manual process codes (0 or 1) is interpreted as an integer.\n",
    "df_sample[\"process_code\"] = df_sample.process_code.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9880f248-2e21-4fae-b5b5-4185d46ad7be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 438, 0: 1542})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the prevalence of the classes.\n",
    "Counter(df_sample.process_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "972b03dd-9367-437d-9747-c7d1cdaaa0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We convert our sentences and codes to respectively an X and y dataset.\n",
    "X = list(df_sample[\"sent_c\"]); y = list(df_sample[\"process_code\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "31d02662-6b92-4f9c-b8a7-1f7c1d4941fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We split it up in train and test data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa06c61-8246-44e7-92d5-645d5c5d05aa",
   "metadata": {},
   "source": [
    "### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9cae4879-e1a4-4fe3-b0e1-a70c2cb943fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.88    0.98      0.93   308.00\n",
      "1                  0.88    0.52      0.66    88.00\n",
      "accuracy           0.88    0.88      0.88     0.88\n",
      "macro avg          0.88    0.75      0.79   396.00\n",
      "weighted avg       0.88    0.88      0.87   396.00\n"
     ]
    }
   ],
   "source": [
    "#We define our vectorizer.\n",
    "vectorizer = TfidfVectorizer(min_df=5, max_df=.5)\n",
    "#We transform our training and test data.\n",
    "X_train_enc = vectorizer.fit_transform(X_train)\n",
    "X_test_enc = vectorizer.transform(X_test)\n",
    "#We define our model.\n",
    "nb = MultinomialNB()\n",
    "#We fit our data.\n",
    "nb.fit(X_train_enc, y_train)\n",
    "#We predict the labels for our test data by the model.\n",
    "y_pred = nb.predict(X_test_enc)\n",
    "#We print the metrics overview.\n",
    "overview_nb = get_metrics_table(y_test, y_pred, feature=\"process information\", model=\"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e1b15-51db-4f8c-8065-fba17aa143b1",
   "metadata": {},
   "source": [
    "### roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c3277b03-35f0-4d66-994c-74e8ef6ac777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define our model.\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "87a4e124-dcf4-41be-b5d0-e72f0b5474a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We tokenize our training and test data.\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ae713081-5741-41af-bb81-4938e1596468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#We define our model.\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2ded8443-be80-48ee-921e-1a1e62e2fd11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define a custom dataset class.\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        #We store the input encodings.\n",
    "        self.encodings = encodings\n",
    "        #We store the corresponding labels.\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        #We create a dictionary to store the current item.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #If labels are provided, we add them to the item dictionary.\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        #We return the item.\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        #We return the length of the input ids list.\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4b195712-b6e9-4d8b-93aa-124740f3a66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We create a train and test dataset.\n",
    "train_dataset = Dataset(train_encodings, y_train)\n",
    "test_dataset = Dataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3dfed23a-6945-4929-8693-1f7a0f9726ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1234, 1: 350})\n",
      "Counter({0: 308, 1: 88})\n"
     ]
    }
   ],
   "source": [
    "#We count the occurance of the labels.\n",
    "print(Counter(train_dataset.labels)); print(Counter(test_dataset.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "163cc19b-df33-4932-970f-e22d43288930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define a function to track the metrics of the model.\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    #We extract the label of the highest probability.\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    #We compare our labels with the predictions.\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    #We calculate additional metrics scores.\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    #We return the metrics.\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6cda86fc-fd40-4207-ac6a-e0c91bc36e86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#We define our training arguments and trainer.\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=9,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=50)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c8731085-1d9d-4a9c-85f2-e3663ee0a1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='891' max='891' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [891/891 02:18, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.388400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.170200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=891, training_loss=0.090747172081912, metrics={'train_runtime': 138.9723, 'train_samples_per_second': 102.582, 'train_steps_per_second': 6.411, 'total_flos': 1113551764047360.0, 'train_loss': 0.090747172081912, 'epoch': 9.0})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We train the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "78710f69-c0cd-49de-b8f9-4d0c11fa6986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5673494935035706,\n",
       " 'eval_accuracy': 0.9040404040404041,\n",
       " 'eval_precision': 0.8579090389016018,\n",
       " 'eval_recall': 0.8693181818181818,\n",
       " 'eval_f1': 0.8633986928104574,\n",
       " 'eval_runtime': 1.2776,\n",
       " 'eval_samples_per_second': 309.963,\n",
       " 'eval_steps_per_second': 19.568,\n",
       " 'epoch': 9.0}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We evaluate our trainer.\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5b6f481c-d4fd-42e3-9e43-773c586a6c04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We save our model.\n",
    "trainer.save_model(\"process_information_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7cef7932-74c4-4293-b9d9-3ee22053f9d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We read in our process info model.\n",
    "model_process_information = RobertaForSequenceClassification.from_pretrained(\"process_information_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "38cb4e26-5200-4312-836b-1e5f520e4c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(40000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_process_information.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b6e3a8dc-e59d-4f13-9956-db512310a3db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define a function to get the model predictions.\n",
    "def get_model_predictions(text, model=source_presence_classifier, output_format=\"labels\"):\n",
    "    #We tokenize the input.\n",
    "    inputs = tokenizer(text,padding = True, truncation = True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #We extract the outputs.\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = np.round(predictions.cpu().detach().numpy(), 3)\n",
    "    \n",
    "    #If the prediction value of the first vlass is higher then that of the second, we return the first class.\n",
    "    if predictions[0][0] > predictions[0][1]:\n",
    "        result = 0\n",
    "    #Else it will be the second class.\n",
    "    else:\n",
    "        result = 1\n",
    "        \n",
    "    if output_format==\"raw\":\n",
    "        return predictions\n",
    "    elif output_format==\"labels\":\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "837fc967-4d1d-4d71-8b57-f289a90db11a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [00:03<00:00, 117.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 304, 1: 92})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_roberta = []\n",
    "\n",
    "#We predict every sentence in our test data.\n",
    "for e in tqdm(X_test):\n",
    "    y = get_model_predictions(e)\n",
    "    y_pred_roberta.append(y)\n",
    "\n",
    "#We count the presence of each class.\n",
    "print(Counter(y_pred_roberta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e91387ca-6ee4-47cc-aeae-12257a0112e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.94    0.93      0.94    308.0\n",
      "1                  0.77    0.81      0.79     88.0\n",
      "accuracy           0.90    0.90      0.90      0.9\n",
      "macro avg          0.86    0.87      0.86    396.0\n",
      "weighted avg       0.91    0.90      0.90    396.0\n"
     ]
    }
   ],
   "source": [
    "#We compare the performance with our manual coding.\n",
    "overview_roberta = get_metrics_table(y_test, y_pred_roberta, feature=\"process information\", model=\"Roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d2133a74-7c58-481d-ba09-0ef15592b420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We add the performance overview to our earlier Naive Bayes performance.\n",
    "overview_process = pd.concat([overview_nb, overview_roberta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1bbd963e-332a-4d24-93cb-cc3fdb0255b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process information</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>no</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.93</td>\n",
       "      <td>308</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process information</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.66</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>process information</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>no</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>308</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process information</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature        model class  precision  recall  f1-score  \\\n",
       "0  process information  Naive Bayes    no       0.88    0.98      0.93   \n",
       "1  process information  Naive Bayes   yes       0.88    0.52      0.66   \n",
       "0  process information      Roberta    no       0.94    0.93      0.94   \n",
       "1  process information      Roberta   yes       0.77    0.81      0.79   \n",
       "\n",
       "   support accuracy  \n",
       "0      308     0.88  \n",
       "1       88           \n",
       "0      308      0.9  \n",
       "1       88           "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a9263e97-9723-4b03-b9ec-1eab08778848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We write away these combined metrics.\n",
    "overview_process.to_csv(\"overview_process.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fbac0-9096-4552-8ba1-3add9ddb6a9c",
   "metadata": {},
   "source": [
    "### predicting process information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4796c15-ad37-4f9b-9e01-7df2549649f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We read in our data with all self referential sentences.\n",
    "df = pd.read_csv(\"21_self_ref_sent.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093bd976-f9f2-4499-876c-9e7203f7493b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"self_referral_text\"] = df[\"self_referral_text\"].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "61925d2c-39ca-4f0e-93a4-9d909829914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function to produce the process info factor.\n",
    "def get_process_info_factor(x, length=max(df.index)):\n",
    "    \n",
    "    presence = x[\"self_referral_presence\"]\n",
    "    self_referral_text = x[\"self_referral_text\"]\n",
    "    text = x[\"txt_text_one\"]\n",
    "    news_source = x[\"news_source\"]; source_pattern = f\"\\\\b({news_source}(\\.nl)?)\\\\b\"\n",
    "    sentences = sent_tokenize(text); n_sentences = len(sentences)\n",
    "    results = []\n",
    "\n",
    "    print(f\"{np.round(x.name/length*100,2)}\", end=\"\\r\")\n",
    "    \n",
    "    #We add a minimum to it, namely if the text only has two sentences, we simply give it a score of 0.\n",
    "    if n_sentences <= 2:\n",
    "        return 0\n",
    "    \n",
    "    #In the case that there are self referral sentences present we do the following:\n",
    "    elif presence==True:\n",
    "        #We loop over the self referrential sentences.\n",
    "        for sent in self_referral_text:\n",
    "            if re.search(source_pattern, sent):\n",
    "                #If an outlet name is present we replace it by SOURCE to reduce outlet bias.\n",
    "                sent = re.sub(source_pattern, \"SOURCE\", sent)\n",
    "            #We then predict the presence or absence of process info in the self referrential sentence.\n",
    "            result = get_model_predictions(sent)\n",
    "            #We append the result (0 or 1) to a list.\n",
    "            results.append(result)\n",
    "        #We then calculate the ratio of the number of process info sentences (the sum of predictions) and divide it by the total sentence length.\n",
    "        return sum(results) / n_sentences\n",
    "    \n",
    "    #If no self referral sentences are present at all it is also directly a score of 0.\n",
    "    elif presence==False:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "68eab6a3-145d-4bee-a810-9839b1b7e192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\r"
     ]
    }
   ],
   "source": [
    "#We apply the function to our data.\n",
    "df[\"process_info_factor\"] = df.apply(lambda x: get_process_info_factor(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b9340985-9bce-443b-9165-5003e0dfa9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    28901.000000\n",
       "mean         0.003703\n",
       "std          0.023204\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          0.545455\n",
       "Name: process_info_factor, dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We print some descriptives.\n",
    "df.process_info_factor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b91e740a-6b16-4219-b1f8-3b938469eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We write it away as a csv.\n",
    "df.to_csv(\"df_w_process_info_factor.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
