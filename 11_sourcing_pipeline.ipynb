{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b223a5-5e6a-4207-b0ea-a25f24603c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We import our libraries.\n",
    "import scipy\n",
    "import accelerate\n",
    "import bitsandbytes\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm; tqdm.pandas()\n",
    "from collections import Counter\n",
    "from deep_translator import GoogleTranslator\n",
    "import re\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4afb61-22b1-4d85-929c-2cd5cb6644af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define a function to create a table of metrics.\n",
    "def get_metrics_table(y_test, y_pred, feature, model):\n",
    "    #Firstly we simply make a dataframe of the metrics classification report using the the test and predict values.\n",
    "    rep = pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    #We round every number to 2 decimals.\n",
    "    print(round(rep, 2))\n",
    "    #We add to it columns in which we can describe which feature was classified and which model was used.\n",
    "    rep[\"feature\"] = feature; rep[\"model\"] = model\n",
    "    rep[[\"precision\", \"f1-score\", \"recall\"]] = rep[[\"precision\", \"f1-score\", \"recall\"]].apply(lambda x: round(x, 2))\n",
    "    #We unround the support column, given that it is a discrete value.\n",
    "    rep[\"support\"] = rep[\"support\"].apply(lambda x: int(x))\n",
    "    #We add the accuracy as a column.\n",
    "    #Since this value is equal for each class, we only want to display it once in the top row.\n",
    "    #For the others we add a blank value.\n",
    "    rep[\"accuracy\"] = [rep[rep.index==\"accuracy\"].values[0][0]] + 4 * [\" \"]\n",
    "    #We only want the first two rows, having the main metrics.\n",
    "    rep = rep[:2]\n",
    "    #We create a simple class name column.\n",
    "    rep[\"class\"] = [\"no\", \"yes\"]\n",
    "    #We output all we need.\n",
    "    rep = rep[[\"feature\", \"model\", \"class\", \"precision\", \"recall\", \"f1-score\", \"support\", \"accuracy\"]][:2]\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4919c-6b46-45f2-8068-c3f972c4a66b",
   "metadata": {},
   "source": [
    "## llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e6bb7-ecfb-410a-98ec-61024983187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We firstly check whether are device is correctly connected to cuda.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"); print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "ec02af7e-4ad7-4ffb-b42a-e153b10fe1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "#We load in our model and tokenizer.\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", load_in_8bit=True)                                                                 \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c122f0-1b96-4168-906a-2472d5b9bba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We load in the intro sentences dataset.\n",
    "df = pd.read_excel(\"11_intro_sent.xlsx\", index_col=0); df = df.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5cd95b-3fc3-4442-bbfd-d93718271cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128689"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We check its length.\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf3b245a-aeaa-4341-b70e-a99035ba66ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'news_source', 'sent', 'sent_index', 'source_presence'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#And its columns.\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b4793-f55f-494d-a388-dd9952b8d531",
   "metadata": {},
   "source": [
    "    f\"You are a researcher into the use of sources in news content. Please answer me this question: are sources used in the following sentence: {translated}? You can choose from the following categories: 0) no: no sources are used or 1) yes: sources are used. Please answer with either 0 (for no) or 1 (for yes).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41da0c6e-e157-417f-bc9e-f12c5b35c772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define a function to get an LLM response.\n",
    "def get_prompt_response(x):\n",
    "    try:\n",
    "        #Firstlu we meed tp translate our input, as the model of interest mostly understands english.\n",
    "        translated = GoogleTranslator(source=\"nl\", target=\"en\").translate(x)\n",
    "        #Secondly we need a prompt, which needs the translated input.\n",
    "        input_string = f\"You are a researcher into the use of sources in news content. Please answer me this question: are sources used in the following sentence: {translated}? You can choose from the following categories: 0) no: no sources are used or 1) yes: sources are used. Please answer with either 0 (for no) or 1 (for yes).\"\n",
    "        #We tokenize this input into tensor input data for the LLM to understand.\n",
    "        inputs = tokenizer(input_string, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "        #We let the model generate its output.\n",
    "        outputs = model.generate(inputs, max_length=9999)\n",
    "        #We decode the output to get a readable result.\n",
    "        result = tokenizer.decode(outputs[0])\n",
    "        #We need a regular expression to clean up the answer.\n",
    "        return re.search(\">(.*)<\", result).group(1).strip()\n",
    "    except:\n",
    "        return \"999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d56cbec-441d-4105-a6dc-4e88b122542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define an empty list.\n",
    "outcome = []\n",
    "#We open up an emptu csv file.\n",
    "with open(\"llm_intro_data.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:      \n",
    "    writer = csv.writer(file)\n",
    "    #We write down our column names of interest.\n",
    "    writer.writerow([\"news_source\", \"index\", \"sent_index\", \"sent\", \"source_presence_flan\"])\n",
    "    #We loop over the rows.\n",
    "    for index, row in df.iterrows():\n",
    "        #We use our function and the sentence as the input.\n",
    "        source_presence_flan = get_prompt_response(row[\"sent\"])\n",
    "        #We append the outcome to a list.\n",
    "        outcome.append(source_presence_flan)\n",
    "        #We continuously print the counts of each outcome.\n",
    "        print(Counter(outcome), end=\"\\r\")\n",
    "        #We write our values of interest away.\n",
    "        writer.writerow([row[\"news_source\"], row[\"index\"], row[\"sent_index\"], row[\"sent\"], source_presence_flan])\n",
    "        file.flush()\n",
    "        #We stop iterating if each possible value (yes or no sourcing) occurred a 1000 times.\n",
    "        if all(outcome.count(str(i)) == 1000 for i in range(1)):\n",
    "            break\n",
    "                     \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "980e43be-f660-4e6d-a280-c1db9eabca50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We read in a version of our results.\n",
    "df_result = pd.read_csv(\"11_intro_sourcing_llm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15277797-72da-409a-84e4-5f8e6294e72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We exclude the rows with false output.\n",
    "df_result = df_result[df_result.source_presence_flan!=999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de7b8cdf-8670-4cf1-91d3-54816f223668",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11343, 1: 1000})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the occurance of each value.\n",
    "Counter(df_result.source_presence_flan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63b45f7e-77de-436b-b2e0-d805a3a43953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We create a custom sampling function just to make sure that we sample random from the no category (0).\n",
    "def custom_sampling(group, min_n=1000):\n",
    "    #We sample a thousand of eahc category.\n",
    "    return group.sample(min(min_n, len(group)), random_state=1)\n",
    "\n",
    "#For each value we sample a thousand, and shuffle them randomly.\n",
    "df_result_sample = df_result.groupby(\"source_presence_flan\", group_keys=False).apply(custom_sampling).sample(frac=1, random_state=1)\n",
    "#We then create an empty column for which we can input our manual annotations\n",
    "df_result_sample[\"source_presence_manual\"] = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9fb02d0-8a5c-4931-8abb-f2f195afbcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We write it away to an excel file.\n",
    "df_result_sample.to_excel(\"sourcing_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dfa6965-2412-43fa-b905-12a051a5cd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1000, 1: 1000})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count whether the sampling went correctly.\n",
    "Counter(df_result_sample.source_presence_flan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f00b9-9cb6-4ac1-84ac-2123054e8ee7",
   "metadata": {},
   "source": [
    "### manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a928e-efb6-4993-a477-fbe4e6ab9d44",
   "metadata": {},
   "source": [
    "__Does the text provide any form of sourcing?__\n",
    "\n",
    "- 1 = True\n",
    "- 0 = False\n",
    "\n",
    "Examples of sources are …\n",
    "\n",
    "- Anonymous sources: sources\n",
    "are not identifiable by withholding full names and disclosing little to no descriptive\n",
    "featur.es\n",
    "    - Sources, insiders, et cetera.\n",
    "- Opaque sources: sources are only partly identifiable by withholding \n",
    "full names and solely providing abstract or overarching feature.s\n",
    "    - The media, press agencies, experts, messages, et cetera.\n",
    "- Explicit sources: sources are directly identifiable by \n",
    "providing full name.s\n",
    "    - Specific news and/or public organizations, governmental bo and es, coprorate entities, identifiable statistics/content/reports/individuls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d711328-4bdd-4c27-993e-eae7642e15ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We read in the data with our manual annotations.\n",
    "df_coded = pd.read_excel(\"11_intro_sourcing_man.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ca9b631-9daf-4b94-b6df-5d3901ba1426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We drop any missing values.\n",
    "df_coded = df_coded.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa908935-d2ed-4d9d-8437-ad0d6a3959ba",
   "metadata": {},
   "source": [
    "### llm metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b1e8e073-bede-4ba3-a710-8bee44ec5629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.85    0.81      0.83  1051.00\n",
      "1                  0.80    0.84      0.82   949.00\n",
      "accuracy           0.83    0.83      0.83     0.83\n",
      "macro avg          0.83    0.83      0.83  2000.00\n",
      "weighted avg       0.83    0.83      0.83  2000.00\n"
     ]
    }
   ],
   "source": [
    "#We comare our annotations with the llm output, using the earlier defined function for the metrics table.\n",
    "overview_llm_presence = get_metrics_table(df_coded.source_presence_manual.astype(int), df_coded.source_presence_flan, feature=\"sourcing presence\", model=\"LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1fe692-e5c4-4e5b-8d65-c43d36a1bcf1",
   "metadata": {},
   "source": [
    "### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199ba1e3-d553-4cc2-8f1c-1bd8694e6b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1051, 1: 949})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the presence in our manual coding.\n",
    "Counter(df_coded.source_presence_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05b8206e-89dd-4b8c-9c51-25a72e4af000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define our X and y, namely the sentences as the X, and the y as the codings.\n",
    "X = list(df_coded[\"sent\"]); y = list(df_coded[\"source_presence_manual\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912232f-d401-462f-8251-f9aa807c4282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We split our dataset into a train and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59910877-c8ae-4f3e-a326-c2147985e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.83    0.73      0.78   210.00\n",
      "1                  0.74    0.84      0.78   190.00\n",
      "accuracy           0.78    0.78      0.78     0.78\n",
      "macro avg          0.78    0.78      0.78   400.00\n",
      "weighted avg       0.79    0.78      0.78   400.00\n"
     ]
    }
   ],
   "source": [
    "#We define our vectorizer,\n",
    "vectorizer = CountVectorizer()\n",
    "#We use it to encode our test and train data.\n",
    "X_train_enc = vectorizer.fit_transform(X_train)\n",
    "X_test_enc = vectorizer.transform(X_test)\n",
    "#We define our model. In this simply a Naive Bayes.\n",
    "nb = MultinomialNB()\n",
    "#We fit the model on our training data.\n",
    "nb.fit(X_train_enc, y_train)\n",
    "#We use it to predict the classes for our test data.\n",
    "y_pred = nb.predict(X_test_enc)\n",
    "#We now compare the NB output with our manual codings.\n",
    "overview_nb_presence = get_metrics_table(y_test, y_pred, feature=\"sourcing presence\", model=\"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7383ccb0-121d-48b7-8bcf-3151048cf7be",
   "metadata": {},
   "source": [
    "### roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0db4027e-d9b1-46ff-9262-610769f4a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our tokenizer from the Roberta dutch model.\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8729ffbf-b5dd-4633-bf28-63d4f2e7fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now use this tokenizer to tokenize our training and test data.\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "54060ea0-f92e-4a09-9695-d37960950036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#We define our model.\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34dec6c-4f4c-44ea-a4c0-ba13d90293c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a custom dataset class.\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        #We store the input encodings.\n",
    "        self.encodings = encodings\n",
    "        #We store the corresponding labels.\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        #We create a dictionary to store the current item.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #If labels are provided, we add them to the item dictionary.\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        #We return the item.\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        #We return the length of the input ids list.\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4f32826d-24a0-4150-98bf-697fa0ee8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our train and test dataset.\n",
    "train_dataset = Dataset(train_encodings, y_train)\n",
    "test_dataset = Dataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b70af0e-4aab-4ee6-8495-9f4aec7953af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 841, 1: 759})\n",
      "Counter({0: 210, 1: 190})\n"
     ]
    }
   ],
   "source": [
    "#We print the occurance of the labels in both datasets.\n",
    "print(Counter(train_dataset.labels)); print(Counter(test_dataset.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4cbed820-d06f-455e-9519-9098a8551abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function to track the metrics of the model.\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    #We extract the label of the highest probability.\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    #We compare our labels with the predictions.\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    #We calculate additional metrics scores.\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true=labels, y_pred=pred, average=\"macro\")\n",
    "    #We return the metrics.\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "139a4890-b37e-4420-a5dc-56dda3854e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#We define our training arguments.\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_steps=100)\n",
    "\n",
    "#We define our trainer, with our model, the training arguments, the train and test datasets and the metric computation function.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90f90336-06ad-4e41-a590-adb1bbb0ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/700 02:00, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.298800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=700, training_loss=0.07789502054452896, metrics={'train_runtime': 120.4477, 'train_samples_per_second': 92.986, 'train_steps_per_second': 5.812, 'total_flos': 1059021997824000.0, 'train_loss': 0.07789502054452896, 'epoch': 7.0})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We train the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "790cd16b-1220-43b1-93a6-e93f138b92aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.30231335759162903,\n",
       " 'eval_accuracy': 0.955,\n",
       " 'eval_precision': 0.9546591932739465,\n",
       " 'eval_recall': 0.9553884711779448,\n",
       " 'eval_f1': 0.9549278846153846,\n",
       " 'eval_runtime': 1.0077,\n",
       " 'eval_samples_per_second': 396.958,\n",
       " 'eval_steps_per_second': 24.81,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We evaluate what we trained.\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "84d32fab-8a2a-4394-91dc-c0f815b07486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We save the trained model.\n",
    "trainer.save_model(\"source_presence_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bbdcd044-7a35-4baa-ae18-efa6e92b1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load the pretrained model.\n",
    "source_presence_classifier = RobertaForSequenceClassification.from_pretrained(\"11_source_presence_classifier\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d69bd036-865c-46ed-bf0f-6d85b933a4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(40000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_presence_classifier.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4100487e-f952-4a9b-b741-c7383ff1208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function to get the model predictions.\n",
    "def get_model_predictions(text, model=source_presence_classifier, output_format=\"labels\"):\n",
    "    #We tokenize the input.\n",
    "    inputs = tokenizer(text,padding = True, truncation = True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #We extract the outputs.\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = np.round(predictions.cpu().detach().numpy(), 3)\n",
    "    \n",
    "    #If the prediction value of the first vlass is higher then that of the second, we return the first class.\n",
    "    if predictions[0][0] > predictions[0][1]:\n",
    "        result = 0\n",
    "    #Else it will be the second class.\n",
    "    else:\n",
    "        result = 1\n",
    "        \n",
    "    if output_format==\"raw\":\n",
    "        return predictions\n",
    "    elif output_format==\"labels\":\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "46797908-a133-4981-a0de-86374d44fa31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:03<00:00, 124.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 206, 1: 194})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_roberta = []\n",
    "\n",
    "#We loop over all our test data.\n",
    "for e in tqdm(X_test):\n",
    "    #We make predictions using the function above.\n",
    "    y = get_model_predictions(e)\n",
    "    #We append the outcomes to a list.\n",
    "    y_pred_roberta.append(y)\n",
    "\n",
    "    \n",
    "#We print the occurance of each class.\n",
    "print(Counter(y_pred_roberta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "65edebc3-8014-4c70-b92e-3a7da74bed37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.97    0.95      0.96   210.00\n",
      "1                  0.94    0.96      0.95   190.00\n",
      "accuracy           0.96    0.96      0.96     0.96\n",
      "macro avg          0.95    0.96      0.95   400.00\n",
      "weighted avg       0.96    0.96      0.96   400.00\n"
     ]
    }
   ],
   "source": [
    "#We get some metrics, comparing it with our manual coding.\n",
    "overview_roberta_presence = get_metrics_table(y_test, y_pred_roberta, feature=\"sourcing presence\", model=\"Roberta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124f975-f29c-4a5e-aafe-e776a0039d3f",
   "metadata": {},
   "source": [
    "## source presence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ad1647b3-e15e-44e8-9864-3406a31df5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128689/128689 [17:40<00:00, 121.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#We make the source presence predictions for every sentence.\n",
    "df[\"p_source_presence\"] = df.sent.progress_apply(lambda x: get_model_predictions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bfcbd94b-13db-4ea4-b1c0-a4a3bdd8e9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 102125, 1: 26564})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the occurance of each class.\n",
    "Counter(df.p_source_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5f362559-880e-47c1-8f9d-8474d24800d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We combine the performance of all models.\n",
    "overview_presence = pd.concat([overview_nb_presence, overview_llm_presence, overview_roberta_presence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "427977e7-2d8d-4c9f-a18c-64d423126d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing presence</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>no</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.78</td>\n",
       "      <td>210</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing presence</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>190</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing presence</td>\n",
       "      <td>LLM</td>\n",
       "      <td>no</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1051</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing presence</td>\n",
       "      <td>LLM</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>949</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing presence</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>no</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>210</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing presence</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "      <td>190</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature        model class  precision  recall  f1-score  support  \\\n",
       "0  sourcing presence  Naive Bayes    no       0.83    0.73      0.78      210   \n",
       "1  sourcing presence  Naive Bayes   yes       0.74    0.84      0.78      190   \n",
       "0  sourcing presence          LLM    no       0.85    0.81      0.83     1051   \n",
       "1  sourcing presence          LLM   yes       0.80    0.84      0.82      949   \n",
       "0  sourcing presence      Roberta    no       0.97    0.95      0.96      210   \n",
       "1  sourcing presence      Roberta   yes       0.94    0.96      0.95      190   \n",
       "\n",
       "  accuracy  \n",
       "0     0.78  \n",
       "1           \n",
       "0     0.83  \n",
       "1           \n",
       "0     0.96  \n",
       "1           "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7f77b8ff-5ebb-4614-bf67-d0b5799f8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We write the table away as a csv.\n",
    "overview_presence.to_csv(\"overview_presence.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a55af4-0dac-4a60-92cb-1d3d490ac7e0",
   "metadata": {},
   "source": [
    "## anonymous sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5dfcbeb2-c1d1-4af1-a49e-672cc462935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function censor the presence of sources in text.\n",
    "def get_source_censored(x):\n",
    "    sent = x[\"sent\"]\n",
    "    news_source = x[\"news_source\"]\n",
    "    source_pattern = f\"\\\\b({news_source}(\\.nl)?)\\\\b\"\n",
    "    \n",
    "    #If the regular expresssion above detects the sourcename in a sentence, then we replace the sourcename with SOURCE.\n",
    "    #We also quickly assess whether a sourcename is present at all, returing 1 if so, and 0 if not.\n",
    "    if re.search(source_pattern, sent):\n",
    "        sent = re.sub(source_pattern, \"SOURCE\", sent)\n",
    "        return 1, sent\n",
    "    else:\n",
    "        return 0, sent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ad40d736-0861-4aee-b212-73bb4772350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128689/128689 [00:16<00:00, 7918.81it/s] \n"
     ]
    }
   ],
   "source": [
    "#We create columns for the two outputs of the above defined function.\n",
    "df[[\"news_source_presence\", \"sent_c\"]] = df.progress_apply(lambda x: pd.Series(get_source_censored(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d3a2e528-1cd6-4092-aaa8-56ffe240491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 127240, 1: 1449})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We print the presence of sources in sentences.\n",
    "Counter(df.news_source_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "211f0da0-baf1-49ca-a9ca-e3232037df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a simple function to detect anonymous sourcing.\n",
    "def get_anonymous_sourcing(x):\n",
    "    #If the word anonymous, sources, or insiders is present we return 1. Or alterations of these words.\n",
    "    if re.search(r\"\\b(anoniem(e)?|bron(nen)?(?! van\\b)|ingewijde(n)?)\\b\", x, flags=re.IGNORECASE):\n",
    "        result = 1\n",
    "    else:\n",
    "        #Else we return 0.\n",
    "        result = 0\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8b11b59b-4705-412b-8079-24f3a37a716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128689/128689 [00:00<00:00, 186713.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#We define this as a new column.\n",
    "df[\"anonymous_sourcing\"] = df.sent.progress_apply(lambda x: get_anonymous_sourcing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b546bcd7-f6dc-4dd9-835a-afa76f3e0f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 128391, 1: 298})"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the presence.\n",
    "Counter(df.anonymous_sourcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5b3920b5-33f5-45ad-a9b5-502233e5201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only keep the rows with a 1 score on anonymous sourcing.\n",
    "df_anonymous = df[df.anonymous_sourcing==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9c1c2f83-5843-4760-a7e8-6ad2fc6b5d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also make a subset of data for when sourcing was presence according to our model prediction.\n",
    "df_present = df[(df.anonymous_sourcing==0) & (df.p_source_presence==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d5cbfeff-0419-4734-915b-7b87a643d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We randomly sample 2000 sentences from this.\n",
    "df_present_sample = df_present.sample(2000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3a9a0101-1aad-4dc9-8909-0c6a9dff9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We add to it the anonymous sentences.\n",
    "df_present_w_anonymous_sample = pd.concat([df_anonymous, df_present_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9c1c5e99-7969-4ab5-8af1-80ee287d03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We write it away to excel.\n",
    "df_present_w_anonymous_sample.to_excel(\"df_present_w_anonymous_sample.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19494d0-8122-4fda-9f02-89e6759dde20",
   "metadata": {},
   "source": [
    "## soucing category manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05a682-04c4-4faa-b9b6-b567cf141e5b",
   "metadata": {},
   "source": [
    "__Which type of source does the text provide?__\n",
    "\n",
    "- 0 = absent\n",
    "- 1 = anonymous\n",
    "- 2 = opaque\n",
    "- 3 = explicit\n",
    "\n",
    "\n",
    "Definitions & examples:\n",
    "\n",
    "- Absent: no sources are used.\n",
    "- Anonymous sources: sources\n",
    "are not identifiable by withholding full names and disclosing little to no descriptive\n",
    "features.\n",
    "    - Sources, insiders, et cetera.\n",
    "- Opaque sources: sources are only partly identifiable by withholding full names and solely providing abstract or overarching features.\n",
    "    - The media, press agencies, experts, messages, et cetera.\n",
    "- Explicit sources: sources are directly identifiable by providing full names.\n",
    "    - Specific news and/or public organizations, governmental bodies and coprorate entities, identifiable statistics/content/reports/individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd4b99b6-b82c-4107-9af1-bfe3bd4d1db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We read in our manual sourcing category codings.\n",
    "df_sourcing = pd.read_excel(\"11_intro_source_cat_man.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "18e174bb-240d-47da-bad5-db191ef4a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove all faulty read in columns.\n",
    "df_sourcing = df_sourcing.loc[:, ~df_sourcing.columns.str.contains(\"Unnamed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7f250d99-8e25-476d-9053-a82e825509d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop the rows where we have missing values for our manual codes.\n",
    "df_sourcing = df_sourcing.dropna(subset=[\"sourcing_cat_man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "fcc413b5-86e9-4757-a398-4a9df97d82a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3.0: 1238, 1.0: 139, 2.0: 620, 0.0: 300})"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the presence of each category.\n",
    "Counter(df_sourcing.sourcing_cat_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "834fcb0f-402c-401f-9891-c5e4b6c21a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We creat an extended metrics table function, given that we now have more then 2 categories to predict.\n",
    "def get_metrics_table_cat(y_test, y_pred, feature, model, cat=[\"absent\", \"anonymous\", \"opaque\", \"explicit\"], n_cat=4):\n",
    "    #We once again transform the metrics classification report to a dataframe.\n",
    "    rep = pd.DataFrame(metrics.classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    #We round every column to 2.\n",
    "    print(round(rep, 2))\n",
    "    #We add the feature and model name as columns.\n",
    "    rep[\"feature\"] = feature; rep[\"model\"] = model\n",
    "    #We include the following metrics scores as ccolumns:\n",
    "    rep[[\"precision\", \"f1-score\", \"recall\"]] = rep[[\"precision\", \"f1-score\", \"recall\"]].apply(lambda x: round(x, 2))\n",
    "    #We add the support value and store it as discrete values.\n",
    "    rep[\"support\"] = rep[\"support\"].apply(lambda x: int(x))\n",
    "    #We include the accuracy once at the top row.\n",
    "    rep[\"accuracy\"] = [rep[rep.index==\"accuracy\"].values[0][0]] + 6 * [\" \"] \n",
    "    #We want the first 4 rows since we have 4 categories.\n",
    "    rep = rep[:n_cat]\n",
    "    #We add the class names for each row.\n",
    "    rep[\"class\"] = cat\n",
    "    #We extract what we need.\n",
    "    rep = rep[[\"feature\", \"model\", \"class\", \"precision\", \"recall\", \"f1-score\", \"support\", \"accuracy\"]][:n_cat]\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1d934-25e6-4934-a78f-e1c11c78729b",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "91c21aab-0d51-4579-bb3a-d4d6e4be80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a new X list with our sentences and now the y is the manual sourcing category codes.\n",
    "X = list(df_sourcing[\"sent_c\"]); y = list(df_sourcing[\"sourcing_cat_man\"].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "8f7b57db-8499-425e-ac32-56b5197ad13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our test and training dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state = 1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "34cf587d-d281-4318-8921-f7f3f806a1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 124, 3: 248, 0: 60, 1: 28})"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the presence in the train and test dataset.\n",
    "Counter(y_train); Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "db2f77a2-4025-45c7-a844-d573a6eca395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our vectorizer.\n",
    "vectorizer = CountVectorizer()\n",
    "#We fit and transform our training data accordingly.\n",
    "X_train_enc = vectorizer.fit_transform(X_train)\n",
    "#We transform the test data.\n",
    "X_test_enc = vectorizer.transform(X_test)\n",
    "#We define a model, here a Logistic Regression.\n",
    "model = LogisticRegression(max_iter=1000).fit(X_train_enc, y_train)\n",
    "#We predict the labels for our test data.\n",
    "y_pred = model.predict(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "c10203c4-eae4-4fcb-8d72-9142bd1cf1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.62    0.22      0.32    60.00\n",
      "1                  0.73    0.39      0.51    28.00\n",
      "2                  0.61    0.50      0.55   124.00\n",
      "3                  0.67    0.87      0.75   248.00\n",
      "accuracy           0.65    0.65      0.65     0.65\n",
      "macro avg          0.66    0.49      0.53   460.00\n",
      "weighted avg       0.65    0.65      0.63   460.00\n"
     ]
    }
   ],
   "source": [
    "#We print the performance compared to our manual coding.\n",
    "overview_lg_sourcing = get_metrics_table_cat(y_test, y_pred, \"sourcing category\", \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "518c5225-5d3b-41e6-9d32-e52bddbb3eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>60</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>opaque</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>124</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>explicit</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.75</td>\n",
       "      <td>248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature                model      class  precision  recall  \\\n",
       "0  sourcing category  Logistic Regression     absent       0.62    0.22   \n",
       "1  sourcing category  Logistic Regression  anonymous       0.73    0.39   \n",
       "2  sourcing category  Logistic Regression     opaque       0.61    0.50   \n",
       "3  sourcing category  Logistic Regression   explicit       0.67    0.87   \n",
       "\n",
       "   f1-score  support accuracy  \n",
       "0      0.32       60     0.65  \n",
       "1      0.51       28           \n",
       "2      0.55      124           \n",
       "3      0.75      248           "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_lg_sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23243f42-6a24-4354-a089-cca9eeddba11",
   "metadata": {},
   "source": [
    "## Roberta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dedf66-e4ec-41b3-8611-e04e563fc06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "NOTE: The following part is largely based on this script:\n",
    "\n",
    "    https://github.com/annekroon/gesis-machine-learning/blob/main/fall-2023/day5/transformers_bert_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "4e5e39a1-3742-4d4b-a4cc-86d9cbc50eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load in some additional libraries.\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.utils import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7da5e104-b39d-4a2a-98f7-c1a7b91691c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load in the tokenizer of the Roberta model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "e3491440-fbd3-4adb-924b-6b45ff805a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We extract the unique labels in our training data.\n",
    "unique_labels = set(label for label in y_train)\n",
    "#We create a function which can convert the labels to ids and the other way around.\n",
    "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "id2label = {id: label for label, id in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "3103eaee-7972-4364-ae50-ce9b16635148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "af8a5f44-72cd-4763-ba86-a7d6a913ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "1b0eda85-0f39-400b-a007-f7a545732142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We encode our texts of the train and testdata.\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
    "test_encodings  = tokenizer(X_test, truncation=True, padding=True)\n",
    "\n",
    "#We encode the labels for the train and test data.\n",
    "train_labels_encoded = [label2id[y] for y in y_train]\n",
    "test_labels_encoded  = [label2id[y] for y in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e43069-4b85-4f33-952f-86dffe7f0438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We define a custom dataset class.\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    #We initialize the dataset with encodings and labels.\n",
    "    def __init__(self, encodings, labels):\n",
    "        #We store the input encodings.\n",
    "        self.encodings = encodings\n",
    "        #We store the corresponding labels.\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        #We create a dictionary to store the current item.\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        #We add labels to the item dictionary.\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        #We return the item.\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        #We return the length of the labels list.\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "812faef2-98c3-4908-97ea-531a86128984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our train and test datasets.\n",
    "train_dataset = MyDataset(train_encodings, train_labels_encoded)\n",
    "test_dataset = MyDataset(test_encodings, test_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fd4ce495-291a-4302-b717-8ce2a6d0cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#We define our model.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels=len(id2label)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e422d66c-e98f-42d8-a430-f909352f43a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create our metrics function to track performance.\n",
    "def compute_metrics(eval_pred):\n",
    "    labels = eval_pred.label_ids\n",
    "    preds = eval_pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    macro_f1 = f1_score(labels, preds, average='macro', sample_weight=compute_sample_weight('balanced', labels))\n",
    "    return {'accuracy': acc, 'macro_f1': macro_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "daba4e02-79ed-4398-bb91-746230f48a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We specifically focus on the macro f1.\n",
    "metric_name = 'macro_f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "ddcca655-7666-4401-aae7-f9b817ec7b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define our training arguments.\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=9,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "    output_dir='./results',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy='steps',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "62167438-eac9-4ea7-8eb3-60bdeb2a7724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#We define our trainer.\n",
    "trainer = Trainer(\n",
    "    model=model,                        \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,       \n",
    "    eval_dataset=test_dataset,           \n",
    "    compute_metrics=compute_metrics     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "111bbc05-3712-4f8f-a501-ce50e81edef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1035' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1035/1035 04:27, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.159100</td>\n",
       "      <td>1.039227</td>\n",
       "      <td>0.539130</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>0.836675</td>\n",
       "      <td>0.691304</td>\n",
       "      <td>0.299618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.812400</td>\n",
       "      <td>0.698177</td>\n",
       "      <td>0.730435</td>\n",
       "      <td>0.369880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.765100</td>\n",
       "      <td>0.644384</td>\n",
       "      <td>0.743478</td>\n",
       "      <td>0.469183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.605230</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.442270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.619300</td>\n",
       "      <td>0.588319</td>\n",
       "      <td>0.763043</td>\n",
       "      <td>0.577657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.557678</td>\n",
       "      <td>0.795652</td>\n",
       "      <td>0.634237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.582825</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.684302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.431900</td>\n",
       "      <td>0.535029</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.732862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.360700</td>\n",
       "      <td>0.584172</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.712577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.736190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.554480</td>\n",
       "      <td>0.821739</td>\n",
       "      <td>0.763457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.661404</td>\n",
       "      <td>0.810870</td>\n",
       "      <td>0.750463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.768281</td>\n",
       "      <td>0.806522</td>\n",
       "      <td>0.724458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.749006</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.742512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.738881</td>\n",
       "      <td>0.813043</td>\n",
       "      <td>0.766023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.869966</td>\n",
       "      <td>0.802174</td>\n",
       "      <td>0.701371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.833036</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.733526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.817876</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.754333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.917136</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.749948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>0.920003</td>\n",
       "      <td>0.823913</td>\n",
       "      <td>0.747161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.863876</td>\n",
       "      <td>0.832609</td>\n",
       "      <td>0.758774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.834918</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.769654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.864942</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.759399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.896675</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.785773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.966815</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.741463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.876645</td>\n",
       "      <td>0.823913</td>\n",
       "      <td>0.756616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.952883</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.752395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>1.163498</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.731972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.937748</td>\n",
       "      <td>0.841304</td>\n",
       "      <td>0.772311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.980659</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.765916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.008200</td>\n",
       "      <td>1.007953</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.768811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.966695</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.766031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>1.136162</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.741339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>1.040815</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.755604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>1.037939</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.766591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.025699</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.771322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>1.096898</td>\n",
       "      <td>0.828261</td>\n",
       "      <td>0.752425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>1.123314</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.747134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>1.051207</td>\n",
       "      <td>0.821739</td>\n",
       "      <td>0.757727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>1.012147</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.782675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.994317</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.761603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.028566</td>\n",
       "      <td>0.832609</td>\n",
       "      <td>0.761074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.022894</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.764147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1.058234</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.756463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.078591</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.756972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>1.086690</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.755001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.090468</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.758221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>1.094815</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.754546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.091642</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.757428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>1.094760</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.757428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1035, training_loss=0.173978473417065, metrics={'train_runtime': 268.0863, 'train_samples_per_second': 61.67, 'train_steps_per_second': 3.861, 'total_flos': 1045041919250472.0, 'train_loss': 0.173978473417065, 'epoch': 9.0})"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We train the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "33dffc97-3f3e-442b-b2d1-706691a00ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8966751098632812,\n",
       " 'eval_accuracy': 0.8391304347826087,\n",
       " 'eval_macro_f1': 0.7857727677552304,\n",
       " 'eval_runtime': 2.3345,\n",
       " 'eval_samples_per_second': 197.043,\n",
       " 'eval_steps_per_second': 12.422,\n",
       " 'epoch': 9.0}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We evaluate the training.\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "9d60b8e4-3ebf-4269-a01e-d73ec8c3076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdubel/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "#We predict the outcomes.\n",
    "predicted_results = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ff10606a-949f-469e-a1cd-7c4985b82c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 4)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It has a shape of 4 given that we have four possible classes.\n",
    "predicted_results.predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "044ca556-0976-4e65-a82f-f71c75c4bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = predicted_results.predictions.argmax(-1) # Get the highest probability prediction\n",
    "#We turn it to a list.\n",
    "predicted_labels = predicted_labels.flatten().tolist() \n",
    "predicted_labels = [id2label[y] for y in predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "00a219ff-42de-4352-b63d-e31f5835208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 125, 3: 258, 1: 33, 0: 44})"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We count the occurance of the predictions.\n",
    "Counter(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f0d20800-ec47-4a65-ba3a-bfd8e446b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We save the model.\n",
    "trainer.save_model(\"sourcing_cat_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "33ee3f89-1951-4c39-813c-41859b8b9830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                  0.75    0.55      0.63    60.00\n",
      "1                  0.76    0.89      0.82    28.00\n",
      "2                  0.79    0.80      0.80   124.00\n",
      "3                  0.89    0.92      0.91   248.00\n",
      "accuracy           0.84    0.84      0.84     0.84\n",
      "macro avg          0.80    0.79      0.79   460.00\n",
      "weighted avg       0.84    0.84      0.84   460.00\n"
     ]
    }
   ],
   "source": [
    "#We create an overview of its performance.\n",
    "overview_roberta_sourcing = get_metrics_table_cat(y_test, predicted_labels, \"sourcing category\", \"Roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "3629319e-658d-4e05-a8e9-8395bab538c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>opaque</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>124</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>explicit</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature    model      class  precision  recall  f1-score  \\\n",
       "0  sourcing category  Roberta     absent       0.75    0.55      0.63   \n",
       "1  sourcing category  Roberta  anonymous       0.76    0.89      0.82   \n",
       "2  sourcing category  Roberta     opaque       0.79    0.80      0.80   \n",
       "3  sourcing category  Roberta   explicit       0.89    0.92      0.91   \n",
       "\n",
       "   support accuracy  \n",
       "0       60     0.84  \n",
       "1       28           \n",
       "2      124           \n",
       "3      248           "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_roberta_sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "aa5b2fce-b7dd-42e3-8427-94d2a2f539ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We combine it with the performance of the LG.\n",
    "overview_sourcing = pd.concat([overview_lg_sourcing, overview_roberta_sourcing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "70610e86-39a2-42d3-b813-63c5bf684ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>model</th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>60</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.51</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>opaque</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.55</td>\n",
       "      <td>124</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>explicit</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.75</td>\n",
       "      <td>248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>opaque</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>124</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sourcing category</td>\n",
       "      <td>Roberta</td>\n",
       "      <td>explicit</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>248</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature                model      class  precision  recall  \\\n",
       "0  sourcing category  Logistic Regression     absent       0.62    0.22   \n",
       "1  sourcing category  Logistic Regression  anonymous       0.73    0.39   \n",
       "2  sourcing category  Logistic Regression     opaque       0.61    0.50   \n",
       "3  sourcing category  Logistic Regression   explicit       0.67    0.87   \n",
       "0  sourcing category              Roberta     absent       0.75    0.55   \n",
       "1  sourcing category              Roberta  anonymous       0.76    0.89   \n",
       "2  sourcing category              Roberta     opaque       0.79    0.80   \n",
       "3  sourcing category              Roberta   explicit       0.89    0.92   \n",
       "\n",
       "   f1-score  support accuracy  \n",
       "0      0.32       60     0.65  \n",
       "1      0.51       28           \n",
       "2      0.55      124           \n",
       "3      0.75      248           \n",
       "0      0.63       60     0.84  \n",
       "1      0.82       28           \n",
       "2      0.80      124           \n",
       "3      0.91      248           "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "854cf217-3dbc-4a08-8ef5-94c2c2c2ec8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We write away these performance tables.\n",
    "overview_sourcing.to_csv(\"overview_sourcing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f84aa15-a304-43cd-85d5-632d2eccf7b3",
   "metadata": {},
   "source": [
    "## predicting sourcing cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e5d8dae9-e838-4434-893f-94feb89e07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We subset the data which either has sources or anonymous sources.\n",
    "df_sourcing = df[(df.p_source_presence==1)|(df.anonymous_sourcing==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "cd0989c3-a4e3-4b6f-b241-7dedf2049fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load in our sourcing category classification model.\n",
    "sourcing_cat_classifier = RobertaForSequenceClassification.from_pretrained(\"sourcing_cat_classifier\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "45e886ff-c26a-412a-9e5f-99cbcc72434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define a function to get predictions.\n",
    "def get_model_predictions(text, model=sourcing_cat_classifier, output_format=\"labels\"):\n",
    "    #We tokenize the text.\n",
    "    inputs = tokenizer(text,padding = True, truncation = True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #We extract the model outputs.\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = np.round(predictions.cpu().detach().numpy(), 3)\n",
    "    #We extract the class with the highest probability.\n",
    "    pred_labels = predictions.argmax(-1)[0]\n",
    "    pred_labels = id2label.get(pred_labels)\n",
    "\n",
    "    if output_format==\"raw\":\n",
    "        return predictions\n",
    "    elif output_format==\"labels\":\n",
    "        return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "ae8703db-ba62-49a7-b77c-4a4fcdff9ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26633/26633 [03:35<00:00, 123.79it/s]\n",
      "/tmp/ipykernel_2386008/2265202836.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sourcing[\"p_sourcing_cat\"] = df_sourcing.sent_c.progress_apply(lambda x: get_model_predictions(x))\n"
     ]
    }
   ],
   "source": [
    "#We use it on every censored sentence within the sourcing data subset.\n",
    "df_sourcing[\"p_sourcing_cat\"] = df_sourcing.sent_c.progress_apply(lambda x: get_model_predictions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "5f10a740-2605-4a87-a464-6324f12ec9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 15010, 0: 2344, 2: 8895, 1: 384})"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We counter the presence of each category as predicted.\n",
    "Counter(df_sourcing.p_sourcing_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "9f36c18f-6c90-4048-b469-440c2111518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We write away to a csv file.\n",
    "df_sourcing.to_csv(\"sourcing_complete.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
